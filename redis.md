# Redis
### 持久化
* RDB (Redis DataBase)
> 通过时段性的保留快照数据，保证当数据丢失时，可以通过快照文件来恢复。

优点：数据恢复速度快

缺点：保存快照的时间间隔中容易丢失数据,备份时需要将数据写入临时文件，占用大量内存
* AOF (append only file)
> 记录每次数据的写操作，保存在aof文件中，重启redis服务之后重新执行以上操作

优点：数据一致性高

缺点：随着操作的不断增加，aof文件会变得越来越大，数据恢复的速度也会明显下降
(重写机制:当aof超过设置的大小时，会压缩文件内容。例如:set test 123和set test 1234可以合并为一条)

[参考资料](https://www.cnblogs.com/itdragon/p/7906481.html)

### 过期键的删除策略
* 定时删除
> 在创建键的时候生成一个timer定时器，当时限到达的时候定时器直接删除该键。

优点：减少内存占用

缺点：占用cpu性能
* 惰性删除
> 在键进行读操作的时候再进行判断是否过期，过期则删除。

优点：减少cpu负担

缺点：占用更多内存

* 定期删除
> 在某个时间段过后监测过期键并进行删除。

特点：属于以上两种策略的折中方案，根据对于时间段的设置和删除键时的持续时间，可以根据实际情况来倾向于保证cpu或内存中的某一方。

	redis使用的过期键值删除策略是：惰性删除加上定期删除，两者配合使用。

[参考资料1](https://blog.csdn.net/ThinkWon/article/details/101522970)

[参考资料2](https://www.cnblogs.com/lukexwang/p/4694094.html)

### 内存淘汰策略
> 当占用的内存超过指定的内存时，已经无法再进行占用内存的写操作（非删除类型的写操作），这时候需要对内存进行淘汰策略以保证接下来的操作。（可占用内存的大小可在redis.conf中的maxmemory进行设置 ）

* noeviction: 不删除策略, 达到最大内存限制时, 如果需要更多内存, 直接返回错误信息。（默认）
* volatile-lru：从已设置过期时间的数据集中挑选最近最少使用的数据淘汰。
* volatile-ttl：从已设置过期时间的数据集中挑选将要过期的数据淘汰。
* volatile-random：从已设置过期时间的数据集中任意选择数据淘汰。
* allkeys-lru：从数据集中挑选最近最少使用的数据淘汰
* allkeys-lfu：从数据集中挑选使用频率最低的数据淘汰。
* volatile-lfu：从已设置过期时间的数据集挑选使用频率最低的数据淘汰。（redis 4）
* allkeys-random：从数据集(server.db[i].dict)中任意选择数据淘汰。（redis 4）

>FIFO：First In First Out，先进先出。判断被存储的时间，离目前最远的数据优先被淘汰。

>LRU：Least Recently Used，最近最少使用。判断最近被使用的时间，目前最远的数据优先被淘汰。

>LFU：Least Frequently Used，最不经常使用。在一段时间内，数据被使用次数最少的，优先被淘汰。

[参考资料1](https://blog.csdn.net/ligupeng7929/article/details/79603060)

[参考资料2](https://blog.csdn.net/zhangchaoyang/article/details/109649331)

#### redis中LRU和LFU实现

redis中的LRU采用的是近似LRU来实现以节省内存，每次采取的是抽取某个数量(maxmemory_samples)的键来淘汰其中被使用时间最远的键。

> 根据Redis作者的说法，每个Redis Object可以挤出24 bits的空间，但24 bits是不够存储两个指针的，而存储一个低位时间戳是足够的，Redis Object以秒为单位存储了对象新建或者更新时的unix time，也就是LRU clock，24 bits数据要溢出的话需要194天，而缓存的数据更新非常频繁，已经足够了。而在LFU中，24bits分为16bits和8bits，高16 bits用来记录最近一次计数器降低的时间ldt，单位是分钟，低8 bits记录计数器数值counter。

> Redis3.0之后又改善了算法的性能，会提供一个待淘汰候选key的pool，里面默认有16个key，按照空闲时间排好序。更新时从Redis键空间随机选择N个key，分别计算它们的空闲时间idle，key只会在pool不满或者空闲时间大于pool里最小的时，才会进入pool，然后从pool中选择空闲时间最大的key淘汰掉。

[参考资料1](https://www.cnblogs.com/linxiyue/p/10955533.html)

[参考资料2](https://www.cnblogs.com/linxiyue/p/10945216.html)

## redis集群

### 主从复制
>分为主服务器和从服务器，一对多的一种模式。
	复制分为全量复制和部分复制，部分复制只是通过命令进行复制，全量复制需要载入主服务器的RDB快照和同步过程中的缓冲区命令。

  从服务器一开始启动的时候，会发送SYNC命令到主服务器，主服务器将执行BGSAVE命令生成RDB文件，发送给从服务器进行数据同步。从节点首先清除自己的旧数据，然后载入接收的RDB文件。同时主服务器会继续处理请求，并把写命令保存到缓存区，当从服务器数据同步结束之后，【部分复制】会执行由主服务器发送来的写命令(从缓存区中取，缓冲区内的命令都执行完了之后和主服务器同步执行新的写命令)


优点：可以实现读写分离，Master服务器只进行写操作的变更和同步，由Slave服务器进行读操作的返回。Slave同样可以接受其它Slaves的连接和同步请求，这样可以有效的分载Master的同步压力

缺点：不具备分区容错性（CAP中最重要的P），主机从机的宕机都会导致前端部分读写请求失败。当主从同步的时候如果出现主机宕机，缓冲区的命令并未完全同步执行，那么就会出现数据不一致的情况。

### 哨兵模式(Sentinel)
>当主服务器中断服务后，可以将一个从服务器升级为主服务器，以便继续提供服务。简单来说就是通过新增哨兵进程来监测服务器的状态，实现分区容错性，当主服务器出现宕机的情况则会选拔一个从服务器来接班。

哨兵的工作方式：

* 每个Sentinel（哨兵）进程以每秒钟一次的频率向整个集群中的Master主服务器，Slave从服务器以及其他Sentinel（哨兵）进程发送一个 PING 命令。
* 如果一个实例（instance）距离最后一次有效回复 PING 命令的时间超过 down-after-milliseconds 选项所指定的值， 则这个实例会被 Sentinel（哨兵）进程标记为主观下线（SDOWN）
* 如果一个Master主服务器被标记为主观下线（SDOWN），则正在监视这个Master主服务器的所有 Sentinel（哨兵）进程要以每秒一次的频率确认Master主服务器的确进入了主观下线状态
* 当有足够数量的 Sentinel（哨兵）进程（大于等于配置文件指定的值）在指定的时间范围内确认Master主服务器进入了主观下线状态（SDOWN）， 则Master主服务器会被标记为客观下线（ODOWN）
* 在一般情况下， 每个 Sentinel（哨兵）进程会以每 10 秒一次的频率向集群中的所有Master主服务器、Slave从服务器发送 INFO 命令。
* 当Master主服务器被 Sentinel（哨兵）进程标记为客观下线（ODOWN）时，Sentinel（哨兵）进程向下线的 Master主服务器的所有 Slave从服务器发送 INFO 命令的频率会从 10 秒一次改为每秒一次。
* 若没有足够数量的 Sentinel（哨兵）进程同意 Master主服务器下线， Master主服务器的客观下线状态就会被移除。若 Master主服务器重新向 Sentinel（哨兵）进程发送 PING 命令返回有效回复，Master主服务器的主观下线状态就会被移除(从客观下线状态重新返回以后只能作为从服务器继续工作---呜呜呜败犬的下场)。

优点：就是在主从复制上增加了系统的高可用性
缺点：主要是需要新增多个哨兵进程进行定时的PING操作，对于CPU的负担更大。(个人猜的想不到其他的)

### redis集群(cluster)

> 其实不管是主从复制还是哨兵模式，本质上其实都是通过同步来保证主从服务器上的数据一致，类似于集群的思想，这就导致全量的数据需要保存到多个地方，内存空间的使用量大幅上升。如果用分布式的思想，将全量数据分为多份，有需要的时候到对应的服务器操作，可以占用较少的内存。以上说的后者，就是cluster模式大致思想。

cluster模式将16384个slot通过类一致性哈希算法来分配到多个Master主服务器节点上(最少3个)，每个主节点还会分配最少一个的Slave节点进行备份，当Master节点宕机时候则会将Slave节点提升为Master节点，以保证集群的高可用性。

#### 类一致哈希

cluster模式没有采取传统的哈希算法(对key计算出一个hash值，然后用哈希值对master数量进行取模。由此就可以将key负载均衡到每一个Redis节点上去)，因为传统哈希算法会产生一个问题，就是当某个节点不可用的时候，会出现重新进行key分配（也就是重新计算所有key的hash值并分配存储），这就导致整个集群的key都受到了影响 ，也就是这一时间下，redis中只存储了极少量的key甚至是没有key，会造成【缓存雪崩】，请求压力都会到数据库。

具体的实现有点懒得写，大概就是某个节点出现问题的话，会把请求顺延到下个节点，也不需要重新key分配这个过程，同时还会通过选举来将该Master节点下的Slave节点进行升级，提升为Master节点。

[参考资料1](https://mp.weixin.qq.com/s/DKrvs7TlwyUeMJKCzbVzjg)

[参考资料2](https://www.cnblogs.com/51life/p/10233340.html)
